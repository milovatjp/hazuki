{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pandas in /usr/local/lib/python3.9/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.9/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/david/Library/Python/3.9/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.9/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/david/Library/Python/3.9/lib/python/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: ginza in /usr/local/lib/python3.9/site-packages (5.2.0)\n",
      "Requirement already satisfied: spacy<4.0.0,>=3.4.4 in /usr/local/lib/python3.9/site-packages (from ginza) (3.7.5)\n",
      "Requirement already satisfied: plac>=1.3.3 in /usr/local/lib/python3.9/site-packages (from ginza) (1.4.3)\n",
      "Requirement already satisfied: SudachiPy<0.7.0,>=0.6.2 in /usr/local/lib/python3.9/site-packages (from ginza) (0.6.8)\n",
      "Requirement already satisfied: SudachiDict-core>=20210802 in /usr/local/lib/python3.9/site-packages (from ginza) (20240409)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ginza) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ginza) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ginza) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ginza) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ginza) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ginza) (8.2.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ginza) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ginza) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ginza) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ginza) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ginza) (0.12.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ginza) (4.66.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ginza) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ginza) (2.7.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ginza) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ginza) (69.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/david/Library/Python/3.9/lib/python/site-packages (from spacy<4.0.0,>=3.4.4->ginza) (24.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ginza) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ginza) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.9/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<4.0.0,>=3.4.4->ginza) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.4.4->ginza) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.4.4->ginza) (2.18.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/david/Library/Python/3.9/lib/python/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.4.4->ginza) (4.12.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.4->ginza) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.4->ginza) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.4->ginza) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.4->ginza) (2024.6.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/site-packages (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.4.4->ginza) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/site-packages (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.4.4->ginza) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.9/site-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->ginza) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.9/site-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->ginza) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.9/site-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->ginza) (13.7.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.9/site-packages (from weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.4.4->ginza) (0.18.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.9/site-packages (from weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.4.4->ginza) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/site-packages (from jinja2->spacy<4.0.0,>=3.4.4->ginza) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.9/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4.0.0,>=3.4.4->ginza) (1.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.9/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->ginza) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/david/Library/Python/3.9/lib/python/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->ginza) (2.18.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.9/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.4.4->ginza) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->ginza) (0.1.2)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: ja_ginza_electra in /usr/local/lib/python3.9/site-packages (5.2.0)\n",
      "Requirement already satisfied: spacy<4.0.0,>=3.4.4 in /usr/local/lib/python3.9/site-packages (from ja_ginza_electra) (3.7.5)\n",
      "Requirement already satisfied: sudachipy<0.7.0,>=0.6.2 in /usr/local/lib/python3.9/site-packages (from ja_ginza_electra) (0.6.8)\n",
      "Requirement already satisfied: sudachidict-core>=20210802 in /usr/local/lib/python3.9/site-packages (from ja_ginza_electra) (20240409)\n",
      "Requirement already satisfied: sudachitra<0.2.0,>=0.1.6 in /usr/local/lib/python3.9/site-packages (from ja_ginza_electra) (0.1.9)\n",
      "Requirement already satisfied: ginza-transformers<0.5.0,>=0.4.0 in /usr/local/lib/python3.9/site-packages (from ja_ginza_electra) (0.4.2)\n",
      "Requirement already satisfied: ginza<5.3.0,>=5.2.0 in /usr/local/lib/python3.9/site-packages (from ja_ginza_electra) (5.2.0)\n",
      "Requirement already satisfied: spacy-transformers<1.2.0,>=1.1.9 in /usr/local/lib/python3.9/site-packages (from ja_ginza_electra) (1.1.9)\n",
      "Requirement already satisfied: plac>=1.3.3 in /usr/local/lib/python3.9/site-packages (from ginza<5.3.0,>=5.2.0->ja_ginza_electra) (1.4.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ja_ginza_electra) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ja_ginza_electra) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ja_ginza_electra) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ja_ginza_electra) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ja_ginza_electra) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ja_ginza_electra) (8.2.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ja_ginza_electra) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ja_ginza_electra) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ja_ginza_electra) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ja_ginza_electra) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ja_ginza_electra) (0.12.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ja_ginza_electra) (4.66.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ja_ginza_electra) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ja_ginza_electra) (2.7.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ja_ginza_electra) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ja_ginza_electra) (69.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/david/Library/Python/3.9/lib/python/site-packages (from spacy<4.0.0,>=3.4.4->ja_ginza_electra) (24.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ja_ginza_electra) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ja_ginza_electra) (1.26.4)\n",
      "Requirement already satisfied: transformers<4.26.0,>=3.4.0 in /usr/local/lib/python3.9/site-packages (from spacy-transformers<1.2.0,>=1.1.9->ja_ginza_electra) (4.25.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.9/site-packages (from spacy-transformers<1.2.0,>=1.1.9->ja_ginza_electra) (2.2.2)\n",
      "Requirement already satisfied: spacy-alignments<1.0.0,>=0.7.2 in /usr/local/lib/python3.9/site-packages (from spacy-transformers<1.2.0,>=1.1.9->ja_ginza_electra) (0.9.1)\n",
      "Requirement already satisfied: logzero~=1.7.0 in /usr/local/lib/python3.9/site-packages (from sudachitra<0.2.0,>=0.1.6->ja_ginza_electra) (1.7.0)\n",
      "Requirement already satisfied: tokenizers>=0.10.3 in /usr/local/lib/python3.9/site-packages (from sudachitra<0.2.0,>=0.1.6->ja_ginza_electra) (0.13.3)\n",
      "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.9/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<4.0.0,>=3.4.4->ja_ginza_electra) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.4.4->ja_ginza_electra) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.4.4->ja_ginza_electra) (2.18.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/david/Library/Python/3.9/lib/python/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.4.4->ja_ginza_electra) (4.12.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.4->ja_ginza_electra) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.4->ja_ginza_electra) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.4->ja_ginza_electra) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.4->ja_ginza_electra) (2024.6.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/site-packages (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.4.4->ja_ginza_electra) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/site-packages (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.4.4->ja_ginza_electra) (0.1.5)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/site-packages (from torch>=1.6.0->spacy-transformers<1.2.0,>=1.1.9->ja_ginza_electra) (3.14.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.9/site-packages (from torch>=1.6.0->spacy-transformers<1.2.0,>=1.1.9->ja_ginza_electra) (1.12.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.9/site-packages (from torch>=1.6.0->spacy-transformers<1.2.0,>=1.1.9->ja_ginza_electra) (3.2.1)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.9/site-packages (from torch>=1.6.0->spacy-transformers<1.2.0,>=1.1.9->ja_ginza_electra) (2024.6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.9/site-packages (from transformers<4.26.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.9->ja_ginza_electra) (0.23.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/site-packages (from transformers<4.26.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.9->ja_ginza_electra) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/site-packages (from transformers<4.26.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.9->ja_ginza_electra) (2024.5.15)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.9/site-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->ja_ginza_electra) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.9/site-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->ja_ginza_electra) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.9/site-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->ja_ginza_electra) (13.7.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.9/site-packages (from weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.4.4->ja_ginza_electra) (0.18.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.9/site-packages (from weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.4.4->ja_ginza_electra) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/site-packages (from jinja2->spacy<4.0.0,>=3.4.4->ja_ginza_electra) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.9/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4.0.0,>=3.4.4->ja_ginza_electra) (1.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.9/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->ja_ginza_electra) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/david/Library/Python/3.9/lib/python/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->ja_ginza_electra) (2.18.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.9/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.4.4->ja_ginza_electra) (1.16.0)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.9/site-packages (from sympy->torch>=1.6.0->spacy-transformers<1.2.0,>=1.1.9->ja_ginza_electra) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->ja_ginza_electra) (0.1.2)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: ja_ginza in /usr/local/lib/python3.9/site-packages (5.2.0)\n",
      "Requirement already satisfied: spacy<4.0.0,>=3.4.4 in /usr/local/lib/python3.9/site-packages (from ja_ginza) (3.7.5)\n",
      "Requirement already satisfied: sudachipy<0.7.0,>=0.6.2 in /usr/local/lib/python3.9/site-packages (from ja_ginza) (0.6.8)\n",
      "Requirement already satisfied: sudachidict-core>=20210802 in /usr/local/lib/python3.9/site-packages (from ja_ginza) (20240409)\n",
      "Requirement already satisfied: ginza<5.3.0,>=5.2.0 in /usr/local/lib/python3.9/site-packages (from ja_ginza) (5.2.0)\n",
      "Requirement already satisfied: plac>=1.3.3 in /usr/local/lib/python3.9/site-packages (from ginza<5.3.0,>=5.2.0->ja_ginza) (1.4.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ja_ginza) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ja_ginza) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ja_ginza) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ja_ginza) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ja_ginza) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ja_ginza) (8.2.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ja_ginza) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ja_ginza) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ja_ginza) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ja_ginza) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ja_ginza) (0.12.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ja_ginza) (4.66.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ja_ginza) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ja_ginza) (2.7.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ja_ginza) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ja_ginza) (69.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/david/Library/Python/3.9/lib/python/site-packages (from spacy<4.0.0,>=3.4.4->ja_ginza) (24.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ja_ginza) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.9/site-packages (from spacy<4.0.0,>=3.4.4->ja_ginza) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.9/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<4.0.0,>=3.4.4->ja_ginza) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.4.4->ja_ginza) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.4.4->ja_ginza) (2.18.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/david/Library/Python/3.9/lib/python/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.4.4->ja_ginza) (4.12.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.4->ja_ginza) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.4->ja_ginza) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.4->ja_ginza) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.4->ja_ginza) (2024.6.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/site-packages (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.4.4->ja_ginza) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/site-packages (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.4.4->ja_ginza) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.9/site-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->ja_ginza) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.9/site-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->ja_ginza) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.9/site-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->ja_ginza) (13.7.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.9/site-packages (from weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.4.4->ja_ginza) (0.18.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.9/site-packages (from weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.4.4->ja_ginza) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/site-packages (from jinja2->spacy<4.0.0,>=3.4.4->ja_ginza) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.9/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4.0.0,>=3.4.4->ja_ginza) (1.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.9/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->ja_ginza) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/david/Library/Python/3.9/lib/python/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->ja_ginza) (2.18.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.9/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.4.4->ja_ginza) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->ja_ginza) (0.1.2)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: spacy in /usr/local/lib/python3.9/site-packages (3.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.9/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.9/site-packages (from spacy) (8.2.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.9/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.9/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.9/site-packages (from spacy) (0.12.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/site-packages (from spacy) (4.66.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.9/site-packages (from spacy) (2.7.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/site-packages (from spacy) (69.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/david/Library/Python/3.9/lib/python/site-packages (from spacy) (24.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/site-packages (from spacy) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.9/site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.9/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.18.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/david/Library/Python/3.9/lib/python/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.6.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.9/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.9/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.9/site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.9/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.18.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.9/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/site-packages (from jinja2->spacy) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.9/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.9/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/david/Library/Python/3.9/lib/python/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.9/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: IPython in /Users/david/Library/Python/3.9/lib/python/site-packages (8.18.1)\n",
      "Requirement already satisfied: decorator in /Users/david/Library/Python/3.9/lib/python/site-packages (from IPython) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/david/Library/Python/3.9/lib/python/site-packages (from IPython) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/david/Library/Python/3.9/lib/python/site-packages (from IPython) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /Users/david/Library/Python/3.9/lib/python/site-packages (from IPython) (3.0.45)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/david/Library/Python/3.9/lib/python/site-packages (from IPython) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /Users/david/Library/Python/3.9/lib/python/site-packages (from IPython) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5 in /Users/david/Library/Python/3.9/lib/python/site-packages (from IPython) (5.14.3)\n",
      "Requirement already satisfied: typing-extensions in /Users/david/Library/Python/3.9/lib/python/site-packages (from IPython) (4.12.0)\n",
      "Requirement already satisfied: exceptiongroup in /Users/david/Library/Python/3.9/lib/python/site-packages (from IPython) (1.2.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/david/Library/Python/3.9/lib/python/site-packages (from IPython) (4.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /Users/david/Library/Python/3.9/lib/python/site-packages (from jedi>=0.16->IPython) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/david/Library/Python/3.9/lib/python/site-packages (from pexpect>4.3->IPython) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/david/Library/Python/3.9/lib/python/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->IPython) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/david/Library/Python/3.9/lib/python/site-packages (from stack-data->IPython) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/david/Library/Python/3.9/lib/python/site-packages (from stack-data->IPython) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /Users/david/Library/Python/3.9/lib/python/site-packages (from stack-data->IPython) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/david/Library/Python/3.9/lib/python/site-packages (from asttokens>=2.1.0->stack-data->IPython) (1.16.0)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "%pip install ginza\n",
    "%pip install ja_ginza_electra\n",
    "%pip install ja_ginza\n",
    "%pip install spacy\n",
    "%pip install IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/usr/local/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd # type: ignore\n",
    "import glob\n",
    "import sys\n",
    "import re\n",
    "import ginza\n",
    "import spacy\n",
    "import os\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.utils.cleanText import clean_text\n",
    "nlp = spacy.load('ja_ginza_electra')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['朝鮮半島、台湾海峡、フィリピン周辺海域。', 'アジア太平洋地域には数多くの危機が伏在するからこそ、対話と交流を通じた信頼醸成は欠かせない。', 'これを長期的に安定した秩序の実現へつなげていくさらなる努力も必要だ。', '地域の防衛担当閣僚や専門家がシンガポールに集まって意見を交わす「アジア安全保障会議」が開かれた。', '会議に合わせて米中の国防相が、１年半ぶりに対面で会談した。', '台湾や南シナ海情勢で軍事緊張が高まる両国だけに激しい応酬になったが、危機時の相互連絡を話し合う作業部会を設けることで合意したのは一歩前進だ。', '特に米国では選挙をにらんで与野党が対中強硬姿勢を競う構図が強まる。', '不測の事態を防ぐだけでなく、こうした政治の動向からも距離を置いた冷静な対応を、双方の軍事当局には望みたい。', 'もっとも、これは最低限の目標と言うべきだろう。', 'アジアのみならず世界の秩序に重い責任を持つ米中両大国に本来求められるのは、中長期的な安保環境の改善だ。', '懸念されるのは、核戦力の増強とミサイル開発が地域で急速に進んでいることだ。', '米中の核兵器をめぐる交渉は昨年１１月以降、伝えられていない。', 'ロシアが無責任な核の脅しを仕掛けている折、米中は核の脅威の低減に向けて協働してほしい。', '中国の董軍国防相は会議での演説で、台湾海峡や南シナ海の緊張について「外部勢力による共謀や支援がある」と批判した。', '名指しは避けたものの米国の関与が問題だと言いたかったのだろう。', 'だが中国軍が南シナ海で岩礁を軍事拠点化するなど海空で存在感を強め、域内を緊張させているのは動かしがたい事実だ。', '会議出席者から言行不一致を指摘する声が相次いだことを、中国は重く受け止めねばならない。', '片や米国も、日本を含む同盟・友好国との対中抑止網の構築に余念がない。', '日本もフィリピン支援を通じて南シナ海への関与を強めている。', 'この状況にプラボウォ・インドネシア次期大統領が「地政学的な緊張の高まりにグローバルサウス（新興国、途上国）は幻滅している」と苦言を呈した。', '軍事力を競い合うのではなく外交を通じた安定実現を望む国々の声に、真摯（しんし）に耳を傾けるべきだ。', 'レーダー照射問題をめぐって日韓が再発防止策と防衛交流再開で合意したのは歓迎すべき動きだ。', '問題を再び政治化せず、日韓関係をアジアの新たな不安定要因にしない冷静な対応が欠かせない。', '有料会員になると会員限定の有料記事もお読みいただけます。', '']\n",
      "[20, 46, 34, 48, 29, 70, 33, 53, 23, 51, 37, 30, 43, 56, 31, 55, 43, 34, 29, 69, 49, 44, 44, 28]\n",
      "The average length of the sentences in news.txt is 41.625 characters\n"
     ]
    }
   ],
   "source": [
    "# read txt news file\n",
    "news_file = '../data/news/news.txt'\n",
    "# Get filename from the news_file path\n",
    "filename = news_file.split('/')[-1]\n",
    "# Read the news file\n",
    "news_txt = open(news_file, 'r').read()\n",
    "# Clean the text\n",
    "news_txt = clean_text(news_txt)\n",
    "# Split the text into sentences \\n\n",
    "news_txt = news_txt.split('\\n')\n",
    "print(news_txt)\n",
    "# remove if there are empty strings \"\"\n",
    "news_txt = [sentence for sentence in news_txt if sentence]\n",
    "\n",
    "# Get the average length of the sentences in news_txt.\n",
    "sentence_lengths = [len(sentence) for sentence in news_txt]\n",
    "print(sentence_lengths)\n",
    "average_sentence_length = sum(sentence_lengths)/len(sentence_lengths)\n",
    "\n",
    "# Print results\n",
    "print(f'The average length of the sentences in {filename} is {average_sentence_length} characters')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'毎日': '食べ', '焼肉+定食': '食べ'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def analyze_ginza(text: str):\n",
    "    ret = {}\n",
    "    doc = nlp(text)\n",
    "    for sentence in doc.sents:\n",
    "        for token in ginza.bunsetu_head_tokens(sentence):\n",
    "            for _relation, sub_phrase in ginza.sub_phrases(token):\n",
    "                ret[str(sub_phrase)] = str(token)\n",
    "    return dict(ret)\n",
    "\n",
    "analyze_ginza(\"毎日焼肉定食を食べます\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/news/news.txt\n",
      "1\t与野党\t対中+強硬+姿勢\t競う\n",
      "1\tロシア\t脅し\t仕掛ける\n",
      "1\t日本\tフィリピン+支援\t強める\n",
      "1\t日本\t関与\t強める\n",
      "1\tプラボウォ+・+インドネシア+次期+大統領\t苦言\t呈する\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "frames = defaultdict(lambda: 0)\n",
    "sentences = set()\n",
    "\n",
    "def tokenize(input_file: str):\n",
    "    print(input_file)\n",
    "    with open(input_file, 'r') as fin:\n",
    "      for line in fin:\n",
    "          try:\n",
    "            doc = nlp(line.rstrip())\n",
    "          except:\n",
    "            continue\n",
    "          for sent in doc.sents:\n",
    "            if sent.text in sentences:\n",
    "              continue\n",
    "            sentences.add(sent.text)\n",
    "            for t in ginza.bunsetu_head_tokens(sent):\n",
    "              if t.pos_ not in {\"ADJ\", \"VERB\"}:\n",
    "                continue\n",
    "              v = ginza.phrase(ginza.lemma_)(t)\n",
    "              dep_phrases = ginza.sub_phrases(t, ginza.phrase(ginza.lemma_), ginza.is_not_stop)\n",
    "              subj = [phrase for dep, phrase in dep_phrases if dep in {\"nsubj\"}]\n",
    "              obj  = [phrase for dep, phrase in dep_phrases if dep in {\"obj\", \"iobj\"}]\n",
    "              for s in subj:\n",
    "                for o in obj:\n",
    "                  frames[(s, o, v)] += 1\n",
    "\n",
    "    for frame, count in sorted(frames.items(), key=lambda t: -t[1]):\n",
    "      print(count, *frame, sep=\"\\t\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Input file\n",
    "    input_file = '../data/news/news.txt'\n",
    "    # Tokenize the input file\n",
    "    tokenize(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         が\n",
      "1        外交\n",
      "2        ぶり\n",
      "3    インドネシア\n",
      "4    シンガポール\n",
      "Name: lemma, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Load newspaper data example json file\n",
    "news = pd.read_json('../data/news/news.json')\n",
    "news_lemmas = news['lemma']\n",
    "\n",
    "print(news_lemmas.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'token_dataframes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 68\u001b[0m\n\u001b[1;32m     66\u001b[0m input_token_dataframe \u001b[38;5;241m=\u001b[39m read_json_files(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/news/*.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_name, df \u001b[38;5;129;01min\u001b[39;00m input_token_dataframe\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 68\u001b[0m     match_tokens(df, \u001b[43mtoken_dataframes\u001b[49m)\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-----------------------------------\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     70\u001b[0m     match_lemmas(df, vocabulary_dataframes)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'token_dataframes' is not defined"
     ]
    }
   ],
   "source": [
    "def read_json_files(path: str):\n",
    "    files = sorted(glob.glob(path))\n",
    "    dataframes = [pd.read_json(file) for file in files]\n",
    "    combined_dataframe = pd.concat(dataframes, ignore_index=True)\n",
    "    return combined_dataframe\n",
    "\n",
    "def read_csv_files(path: str):\n",
    "    files = sorted(glob.glob(path))\n",
    "    dataframes = [pd.read_csv(file) for file in files]\n",
    "    combined_dataframe = pd.concat(dataframes, ignore_index=True)\n",
    "    return combined_dataframe\n",
    "\n",
    "def match_tokens(input_dataframe, token_dataframes):\n",
    "    # Creamos una nueva columna en el dataframe de entrada que es la concatenación de 'lemma' y 'pos'\n",
    "    input_dataframe['lemma_pos'] = input_dataframe['lemma'] + '_' + input_dataframe['pos']\n",
    "    # Convertimos los lemas del dataframe de entrada a un conjunto (eliminando duplicados)\n",
    "    input_lemmas_pos = set(input_dataframe['lemma_pos'].dropna())\n",
    "    matching_results = {}\n",
    "    total_matching_lemmas_pos = 0\n",
    "    # Iteramos sobre cada dataframe en token_dataframes\n",
    "    for file_name, df in token_dataframes.items():\n",
    "        # Creamos una nueva columna en el dataframe actual que es la concatenación de 'lemma' y 'pos'\n",
    "        df['lemma_pos'] = df['lemma'] + '_' + df['pos']\n",
    "        # Convertimos los lemas del dataframe actual a un conjunto (eliminando duplicados)\n",
    "        token_lemmas_pos = set(df['lemma_pos'].dropna())\n",
    "        # Encontramos la intersección de los dos conjuntos (lemas que están en ambos)\n",
    "        matching_lemmas_pos = input_lemmas_pos & token_lemmas_pos\n",
    "        num_matching_lemmas_pos = len(matching_lemmas_pos)\n",
    "        total_matching_lemmas_pos += num_matching_lemmas_pos\n",
    "        # Calculamos el porcentaje de lemas coincidentes\n",
    "        percentage_matching_lemmas_pos = (num_matching_lemmas_pos / len(input_lemmas_pos)) * 100\n",
    "        matching_results[file_name] = (num_matching_lemmas_pos, percentage_matching_lemmas_pos)\n",
    "        print(f'{file_name}')\n",
    "        print(f'\\tTotal matching: {num_matching_lemmas_pos} - {percentage_matching_lemmas_pos:.2f}%')\n",
    "        # Eliminamos los lemas coincidentes de input_lemmas para no contarlos más de una vez\n",
    "        input_lemmas_pos -= matching_lemmas_pos\n",
    "    print(f'Total matching: {total_matching_lemmas_pos} - {(total_matching_lemmas_pos / len(input_lemmas_pos)) * 100:.2f}%')\n",
    "\n",
    "def match_lemmas(input_dataframe, vocabulary_dataframes):\n",
    "    input_lemmas = input_dataframe['lemma']\n",
    "    total_matching_hiragana = 0\n",
    "    total_matching_kanji = 0\n",
    "    for file_name, df in vocabulary_dataframes.items():\n",
    "        matching_kanji = []\n",
    "        matching_hiragana = []\n",
    "        kanji_lemmas = df['Kanji'].dropna()\n",
    "        hiragana_lemmas = df['Hiragana'].dropna()\n",
    "        matching_kanji.extend(input_lemmas[input_lemmas.isin(kanji_lemmas)])\n",
    "        num_matching_kanji = len(matching_kanji)\n",
    "        total_matching_kanji += num_matching_kanji\n",
    "        matching_hiragana.extend(input_lemmas[input_lemmas.isin(hiragana_lemmas)])\n",
    "        num_matching_hiragana = len(matching_hiragana)\n",
    "        total_matching_hiragana += num_matching_hiragana\n",
    "        percentage_matching_kanji = (num_matching_kanji / len(input_lemmas)) * 100\n",
    "        percentage_matching_hiragana = (num_matching_hiragana / len(input_lemmas)) * 100\n",
    "        print(f'{file_name}')\n",
    "        print(f'\\tTotal matching Kanji: {num_matching_kanji} - {percentage_matching_kanji:.2f}%')\n",
    "        print(f'\\tTotal matching Hiragana: {num_matching_hiragana} - {percentage_matching_hiragana:.2f}%')\n",
    "        print(f'\\tTotal cumulative matching: {num_matching_kanji + num_matching_hiragana} - {(percentage_matching_kanji + percentage_matching_hiragana):.2f}%')\n",
    "        print('\\n')\n",
    "    print(f'Total matching Kanji: {total_matching_kanji} - {(total_matching_kanji / len(input_lemmas)) * 100:.2f}%')\n",
    "    print(f'Total matching Hiragana: {total_matching_hiragana} - {(total_matching_hiragana / len(input_lemmas)) * 100:.2f}%')\n",
    "\n",
    "    return matching_kanji, matching_hiragana\n",
    "\n",
    "input_token_dataframe = read_json_files('../data/news/*.json')\n",
    "for file_name, df in input_token_dataframe.items():\n",
    "    match_tokens(df, token_dataframes)\n",
    "    print('\\n-----------------------------------\\n')\n",
    "    match_lemmas(df, vocabulary_dataframes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/tokens/lvl0Tokens.json: 205 matching lemmas (8.39%)\n",
      "../data/tokens/lvl1Tokens.json: 173 matching lemmas (9.77%)\n",
      "../data/tokens/lvl2Tokens.json: 214 matching lemmas (8.98%)\n",
      "../data/tokens/lvl3Tokens.json: 213 matching lemmas (8.74%)\n",
      "../data/tokens/lvl4Tokens.json: 194 matching lemmas (7.95%)\n",
      "295\n",
      "Total matching lemmas: 999\n",
      "Total lemmas: 11474\n",
      "Cumulative percentage of matching lemmas: 8.71%\n",
      "Total matching kanji in n1vocab.csv: 43 - 1.24%\n",
      "Total matching hiragana in n1vocab.csv: 22 - 0.63%\n",
      "Total matching kanji in n2vocab.csv: 11 - 0.60%\n",
      "Total matching hiragana in n2vocab.csv: 22 - 1.20%\n",
      "Total matching kanji in n3vocab.csv: 49 - 2.67%\n",
      "Total matching hiragana in n3vocab.csv: 29 - 1.58%\n",
      "Total matching kanji in n4vocab.csv: 13 - 2.05%\n",
      "Total matching hiragana in n4vocab.csv: 11 - 1.74%\n",
      "Total matching kanji in n5vocab.csv: 17 - 2.54%\n",
      "Total matching hiragana in n5vocab.csv: 23 - 3.44%\n",
      "Total matching kanji: 133\n",
      "Cumulative percentage of matching kanji: 45.08%\n",
      "Total matching hiragana: 107\n",
      "Cumulative percentage of matching hiragana: 36.27%\n"
     ]
    }
   ],
   "source": [
    "# Get a list of all token json files in ../data/tokens ordered by filename\n",
    "token_files = sorted(glob.glob('../data/tokens/*.json'))\n",
    "total_matching_lemmas = 0\n",
    "total_lemmas = 0\n",
    "\n",
    "# Read all the json files in ../data/tokens\n",
    "for token_file in token_files:\n",
    "    # Read the json file\n",
    "    token_data = pd.read_json(token_file)\n",
    "    # Get the lemma column\n",
    "    token_lemma = token_data['lemma']\n",
    "    # Chek if the news_lemma is in the token_lemma\n",
    "    matching_lemmas = token_lemma[token_lemma.isin(news_lemmas)]\n",
    "    # Get the number of matching lemmas\n",
    "    num_matching_lemmas = matching_lemmas.size\n",
    "    # Get percentage of matching lemmas\n",
    "    percentage_matching_lemmas = num_matching_lemmas / token_lemma.size\n",
    "    # Increase the total number of matching lemmas\n",
    "    total_matching_lemmas += num_matching_lemmas\n",
    "    # Increase the total number of lemmas\n",
    "    total_lemmas += token_lemma.size\n",
    "    # Print the results\n",
    "    print(f'{token_file}: {num_matching_lemmas} matching lemmas ({percentage_matching_lemmas:.2%})')\n",
    "    \n",
    "# Calculate the cumulative percentage of matching lemmas\n",
    "cumulative_percentage_matching_lemmas = total_matching_lemmas / total_lemmas\n",
    "\n",
    "print(len(news_lemmas))\n",
    "\n",
    "# Print the cumulative percentage of matching lemmas\n",
    "print(f'Total matching lemmas: {total_matching_lemmas}')\n",
    "print(f'Total lemmas: {total_lemmas}')\n",
    "print(f'Cumulative percentage of matching lemmas: {cumulative_percentage_matching_lemmas:.2%}')\n",
    "\n",
    "# Get a list of all vocabulary files in ../data/ sorted by filename\n",
    "vocabulary_files = sorted(glob.glob('../data/vocabulary/*.csv'))\n",
    "total_matching_kanji = 0\n",
    "total_matching_hiragana = 0\n",
    "total_news_lemmas = news_lemmas.size\n",
    "\n",
    "# Read all the csv files in ../data/vocabulary\n",
    "for vocabulary_file in vocabulary_files:\n",
    "    # Get fileName\n",
    "    fileName = vocabulary_file.split('/')[-1]\n",
    "    # Read the csv file\n",
    "    vocabulary_df = pd.read_csv(vocabulary_file)\n",
    "    # Get the kanji column\n",
    "    kanji_list = vocabulary_df['Kanji']\n",
    "    # Get the hiragana column\n",
    "    hiragana_list = vocabulary_df['Hiragana']\n",
    "    # Compare news_lemmas with kanji_list\n",
    "    matching_kanji = news_lemmas[news_lemmas.isin(kanji_list)]\n",
    "    # Get the number of matching kanji\n",
    "    num_matching_kanji = len(matching_kanji)\n",
    "    # Get the percentage of matching kanji\n",
    "    percentage_matching_kanji = (num_matching_kanji / len(kanji_list)) * 100\n",
    "    # Increase the total number of matching kanji\n",
    "    total_matching_kanji += num_matching_kanji\n",
    "\n",
    "    # Compare news_lemmas with hiragana_list\n",
    "    matching_hiragana = news_lemmas[news_lemmas.isin(hiragana_list)]\n",
    "    # Get the number of matching hiragana\n",
    "    num_matching_hiragana = len(matching_hiragana)\n",
    "    # Get the percentage of matching hiragana\n",
    "    percentage_matching_hiragana = (num_matching_hiragana / len(hiragana_list)) * 100\n",
    "    # Increase the total number of matching hiragana\n",
    "    total_matching_hiragana += num_matching_hiragana\n",
    "\n",
    "    # Print the results by vocabulary file\n",
    "    print(f'Total matching kanji in {fileName}: {num_matching_kanji} - {percentage_matching_kanji:.2f}%')\n",
    "    print(f'Total matching hiragana in {fileName}: {num_matching_hiragana} - {percentage_matching_hiragana:.2f}%')\n",
    "\n",
    "# Calculate the cumulative percentage of matching kanji\n",
    "cumulative_percentage_matching_kanji = total_matching_kanji / total_news_lemmas\n",
    "cumulative_percentage_matching_hiragana = total_matching_hiragana / total_news_lemmas\n",
    "\n",
    "# Print the cumulative percentage of matching kanji\n",
    "print(f'Total matching kanji: {total_matching_kanji}')\n",
    "print(f'Cumulative percentage of matching kanji: {cumulative_percentage_matching_kanji:.2%}')\n",
    "print(f'Total matching hiragana: {total_matching_hiragana}')\n",
    "print(f'Cumulative percentage of matching hiragana: {cumulative_percentage_matching_hiragana:.2%}')\n",
    "\n",
    "# Save matching kanji to a csv file\n",
    "matching_kanji_df = pd.DataFrame(matching_kanji)\n",
    "matching_kanji_df.to_csv('../data/matching_kanji.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matching kanji in n1vocab.csv: 43 - 1.24%\n",
      "Total matching hiragana in n1vocab.csv: 22 - 0.63%\n",
      "Total matching kanji in n2vocab.csv: 11 - 0.60%\n",
      "Total matching hiragana in n2vocab.csv: 22 - 1.20%\n",
      "Total matching kanji in n3vocab.csv: 49 - 2.67%\n",
      "Total matching hiragana in n3vocab.csv: 29 - 1.58%\n",
      "Total matching kanji in n4vocab.csv: 13 - 2.05%\n",
      "Total matching hiragana in n4vocab.csv: 11 - 1.74%\n",
      "Total matching kanji in n5vocab.csv: 17 - 2.54%\n",
      "Total matching hiragana in n5vocab.csv: 23 - 3.44%\n",
      "Total matching kanji: 133\n",
      "Cumulative percentage of matching kanji: 45.08%\n",
      "Total matching hiragana: 107\n",
      "Cumulative percentage of matching hiragana: 36.27%\n"
     ]
    }
   ],
   "source": [
    "# Get a list of all vocabulary files in ../data/ sorted by filename\n",
    "vocabulary_files = sorted(glob.glob('../data/vocabulary/*.csv'))\n",
    "total_matching_kanji = 0\n",
    "total_matching_hiragana = 0\n",
    "total_news_lemmas = news_lemmas.size\n",
    "\n",
    "# Read all the csv files in ../data/vocabulary\n",
    "for vocabulary_file in vocabulary_files:\n",
    "    # Get fileName\n",
    "    fileName = vocabulary_file.split('/')[-1]\n",
    "    # Read the csv file\n",
    "    vocabulary_df = pd.read_csv(vocabulary_file)\n",
    "    # Get the kanji column\n",
    "    kanji_list = vocabulary_df['Kanji']\n",
    "    # Get the hiragana column\n",
    "    hiragana_list = vocabulary_df['Hiragana']\n",
    "    # Compare news_lemmas with kanji_list\n",
    "    matching_kanji = news_lemmas[news_lemmas.isin(kanji_list)]\n",
    "    # Get the number of matching kanji\n",
    "    num_matching_kanji = len(matching_kanji)\n",
    "    # Get the percentage of matching kanji\n",
    "    percentage_matching_kanji = (num_matching_kanji / len(kanji_list)) * 100\n",
    "    # Increase the total number of matching kanji\n",
    "    total_matching_kanji += num_matching_kanji\n",
    "\n",
    "    # Compare news_lemmas with hiragana_list\n",
    "    matching_hiragana = news_lemmas[news_lemmas.isin(hiragana_list)]\n",
    "    # Get the number of matching hiragana\n",
    "    num_matching_hiragana = len(matching_hiragana)\n",
    "    # Get the percentage of matching hiragana\n",
    "    percentage_matching_hiragana = (num_matching_hiragana / len(hiragana_list)) * 100\n",
    "    # Increase the total number of matching hiragana\n",
    "    total_matching_hiragana += num_matching_hiragana\n",
    "\n",
    "    # Print the results by vocabulary file\n",
    "    print(f'Total matching kanji in {fileName}: {num_matching_kanji} - {percentage_matching_kanji:.2f}%')\n",
    "    print(f'Total matching hiragana in {fileName}: {num_matching_hiragana} - {percentage_matching_hiragana:.2f}%')\n",
    "\n",
    "# Calculate the cumulative percentage of matching kanji\n",
    "cumulative_percentage_matching_kanji = total_matching_kanji / total_news_lemmas\n",
    "cumulative_percentage_matching_hiragana = total_matching_hiragana / total_news_lemmas\n",
    "\n",
    "# Print the cumulative percentage of matching kanji\n",
    "print(f'Total matching kanji: {total_matching_kanji}')\n",
    "print(f'Cumulative percentage of matching kanji: {cumulative_percentage_matching_kanji:.2%}')\n",
    "print(f'Total matching hiragana: {total_matching_hiragana}')\n",
    "print(f'Cumulative percentage of matching hiragana: {cumulative_percentage_matching_hiragana:.2%}')\n",
    "\n",
    "# Save matching kanji to a csv file\n",
    "matching_kanji_df = pd.DataFrame(matching_kanji)\n",
    "matching_kanji_df.to_csv('../data/matching_kanji.csv', index=False)\n",
    "\n",
    "\n",
    "    # # Compare news_lemmas with kanji_list\n",
    "    # matching_kanji = news_lemmas[news_lemmas.isin(kanji_list)]\n",
    "    # print(f'filename {fileName} matching_kanji {matching_kanji}')\n",
    "    # # Get the number of matching kanji\n",
    "    # num_matching_kanji = len(matching_kanji)\n",
    "    # # Get the percentage of matching kanji\n",
    "    # percentage_matching_kanji = (num_matching_kanji / len(kanji_list)) * 100\n",
    "    # # Increase the total number of matching kanji\n",
    "    # total_matching_kanji += num_matching_kanji\n",
    "\n",
    "#     # Get the hiragana column\n",
    "#     hiragana_list = vocabulary_df['Hiragana']\n",
    "#     # Compare news_lemmas with hiragana_list\n",
    "#     matching_hiragana = news_lemmas[news_lemmas.isin(hiragana_list)]\n",
    "#     # Get the number of matching hiragana\n",
    "#     num_matching_hiragana = len(matching_hiragana)\n",
    "#     # Get the percentage of matching hiragana\n",
    "#     percentage_matching_hiragana = (num_matching_hiragana / len(hiragana_list)) * 100\n",
    "#     # Increase the total number of matching hiragana\n",
    "#     total_matching_hiragana += num_matching_hiragana\n",
    "\n",
    "#     # Print the results by vocabulary file\n",
    "#     print(f'Total matching kanji in {fileName}: {num_matching_kanji} - {percentage_matching_kanji:.2f}%')\n",
    "#     print(f'Total matching hiragana in {fileName}: {num_matching_hiragana} - {percentage_matching_hiragana:.2f}%')\n",
    "\n",
    "# # Calculate the cumulative percentage of matching kanji\n",
    "# cumulative_percentage_matching_kanji = total_matching_kanji / total_news_lemmas\n",
    "# cumulative_percentage_matching_hiragana = total_matching_hiragana / total_news_lemmas\n",
    "\n",
    "# # Print the cumulative percentage of matching kanji\n",
    "# print(f'Total matching kanji: {total_matching_kanji}')\n",
    "# print(f'Cumulative percentage of matching kanji: {cumulative_percentage_matching_kanji:.2%}')\n",
    "# print(f'Total matching hiragana: {total_matching_hiragana}')\n",
    "# print(f'Cumulative percentage of matching hiragana: {cumulative_percentage_matching_hiragana:.2%}')\n",
    "\n",
    "# Save matching kanji to a csv file\n",
    "# matching_kanji_df = pd.DataFrame(matching_kanji)\n",
    "# matching_kanji_df.to_csv('../data/matching_kanji.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for |: 'str' and 'bool'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:362\u001b[0m, in \u001b[0;36mna_logical_op\u001b[0;34m(x, y, op)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;66;03m# For exposition, write:\u001b[39;00m\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;66;03m#  yarr = isinstance(y, np.ndarray)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;66;03m# Then Cases where this goes through without raising include:\u001b[39;00m\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;66;03m#  (xint or xbool) and (yint or bool)\u001b[39;00m\n\u001b[0;32m--> 362\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for |: 'str' and 'bool'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 47\u001b[0m\n\u001b[1;32m     44\u001b[0m input_token_dataframe \u001b[38;5;241m=\u001b[39m read_json_files(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/news/*.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     45\u001b[0m vocaabulary_dataframes \u001b[38;5;241m=\u001b[39m read_csv_files(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/vocabulary/*.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 47\u001b[0m \u001b[43mmatch_vocabulary\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_token_dataframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocabulary_dataframes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mN2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[61], line 25\u001b[0m, in \u001b[0;36mmatch_vocabulary\u001b[0;34m(input_dataframe, vocabulary_dataframes, language_level)\u001b[0m\n\u001b[1;32m     21\u001b[0m input_lemmas \u001b[38;5;241m=\u001b[39m input_dataframe[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlemma\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Find matching rows in the input dataframe\u001b[39;00m\n\u001b[1;32m     24\u001b[0m matching_rows \u001b[38;5;241m=\u001b[39m input_dataframe[\n\u001b[0;32m---> 25\u001b[0m     \u001b[43minput_lemmas\u001b[49m\u001b[43m[\u001b[49m\u001b[43minput_lemmas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkanji_list\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m|\u001b[39;49m\u001b[43m \u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_lemmas\u001b[49m\u001b[43m[\u001b[49m\u001b[43minput_lemmas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhiragana_list\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     27\u001b[0m ]\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m matching_rows\u001b[38;5;241m.\u001b[39mempty:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/arraylike.py:78\u001b[0m, in \u001b[0;36mOpsMixin.__or__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__or__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__or__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_logical_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mor_\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/series.py:6130\u001b[0m, in \u001b[0;36mSeries._logical_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6127\u001b[0m lvalues \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   6128\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 6130\u001b[0m res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogical_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:454\u001b[0m, in \u001b[0;36mlogical_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;66;03m# i.e. scalar\u001b[39;00m\n\u001b[1;32m    452\u001b[0m     is_other_int_dtype \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mis_integer(rvalues)\n\u001b[0;32m--> 454\u001b[0m res_values \u001b[38;5;241m=\u001b[39m \u001b[43mna_logical_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;66;03m# For int vs int `^`, `|`, `&` are bitwise operators and return\u001b[39;00m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;66;03m#   integer dtypes.  Otherwise these are boolean ops\u001b[39;00m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (left\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miu\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_other_int_dtype):\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:369\u001b[0m, in \u001b[0;36mna_logical_op\u001b[0;34m(x, y, op)\u001b[0m\n\u001b[1;32m    367\u001b[0m     x \u001b[38;5;241m=\u001b[39m ensure_object(x)\n\u001b[1;32m    368\u001b[0m     y \u001b[38;5;241m=\u001b[39m ensure_object(y)\n\u001b[0;32m--> 369\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mlibops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvec_binop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;66;03m# let null fall thru\u001b[39;00m\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mis_scalar(y)\n",
      "File \u001b[0;32mops.pyx:252\u001b[0m, in \u001b[0;36mpandas._libs.ops.vec_binop\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mops.pyx:245\u001b[0m, in \u001b[0;36mpandas._libs.ops.vec_binop\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for |: 'str' and 'bool'"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "def match_vocabulary(input_dataframe, vocabulary_dataframes, language_level):\n",
    "    matching_tokens = {}\n",
    "\n",
    "    # Define the language levels in order\n",
    "    language_levels = ['N1', 'N2', 'N3', 'N4', 'N5']\n",
    "\n",
    "    for file_name, vocabulary_df in vocabulary_dataframes.items():\n",
    "        # Get Level from file_name the filename is in the two first characters\n",
    "        level = file_name[:2].upper()\n",
    "\n",
    "        # If the level is higher than the language_level, skip the dataframe\n",
    "        if language_levels.index(level) < language_levels.index(language_level.upper()):\n",
    "\n",
    "            # Get the kanji column\n",
    "            kanji_list = vocabulary_df['Kanji']\n",
    "            # Get the hiragana column\n",
    "            hiragana_list = vocabulary_df['Hiragana']\n",
    "            # Get the input_dataframe lemma column\n",
    "            input_lemmas = input_dataframe['lemma']\n",
    "\n",
    "            # Find matching rows in the input dataframe\n",
    "            matching_rows = input_dataframe[\n",
    "                input_lemmas[input_lemmas.isin(kanji_list)] | \n",
    "                input_lemmas[input_lemmas.isin(hiragana_list)]\n",
    "            ]\n",
    "\n",
    "            # \n",
    "            if not matching_rows.empty:\n",
    "                matching_tokens[level] = matching_rows\n",
    "\n",
    "    # Concatenate all matching tokens into one dataframe\n",
    "    if matching_tokens:\n",
    "        coincidences_df = pd.concat(matching_tokens.values())\n",
    "        # Save the coincidences_df to a csv file\n",
    "        # coincidences_df.to_csv('../data/coincidences.csv', index=False)   \n",
    "        display(coincidences_df)\n",
    "    else:\n",
    "        print('No matching tokens found')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Match the tokens\n",
    "    input_token_dataframe = read_json_files('../data/news/*.json')\n",
    "    vocaabulary_dataframes = read_csv_files('../data/vocabulary/*.csv')\n",
    "\n",
    "    match_vocabulary(input_token_dataframe, vocabulary_dataframes, 'N2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "languague level N1 is higher than N3\n",
      "languague level N2 is higher than N3\n",
      "N1 vocabulary:\n",
      "Kanji Hiragana                                                                                                      English\n",
      "    相       あい                                                                                   together, mutually, fellow\n",
      "  集まる     あつまる                                                                           to gather, to collect, to assemble\n",
      "    網       あみ                                                                                                 net, network\n",
      "   或る       ある                                                                                        a certain..., some...\n",
      "  NaN       いく                                                                                           to come, to orgasm\n",
      "    軍      いくさ                                                                                 war, battle, campaign, fight\n",
      "   入る       いる                                             to get in, to go in, to come in, to flow into, to set, to set in\n",
      "受け止める    うけとめる                                                             to catch, to stop the blow, to react to, to take\n",
      "   動き      うごき                                                               movement, activity, trend, development, change\n",
      "    尾        お                                                                                                  tail, ridge\n",
      "    於        お                                                                                                   at, in, on\n",
      "   海峡    かいきょう                                                                                                      channel\n",
      "   会談     かいだん                                                              conversation, conference, discussion, interview\n",
      "   開発     かいはつ                                                                                    development, exploitation\n",
      "    核       かく                                                                                              nucleus, kernel\n",
      "  傾ける    かたむける to incline, to list, to bend, to lean, to tip, to tilt, to slant, to concentrate on, to ruin (a country), to\n",
      "  交わす      かわす                                          to exchange (messages), to dodge, to parry, to avoid, to turn aside\n",
      "   関与      かんよ                                          participation, taking part in, participating in, being concerned in\n",
      "   危機       きき                                                                                                       crisis\n",
      "   強硬    きょうこう                                                      firm, vigorous, unbending, unyielding, strong, stubborn\n",
      "   距離      きょり                                                                                              distance, range\n",
      "   軍事      ぐんじ                                                                                             military affairs\n",
      "   限定     げんてい                                                                                           limit, restriction\n",
      "    溝       こう                                          10^38, hundred undecillion (American), hundred sextillion (British)\n",
      "    校       こう                                                                                                       #NAME?\n",
      "   交渉    こうしょう                                                                        negotiations, discussions, connection\n",
      "   国防     こくぼう                                                                                             national defence\n",
      "   此の       この                                                                                                         this\n",
      "   此れ       これ                                                                                                         this\n",
      "   合意      ごうい                                                                     agreement, consent, mutual understanding\n",
      " 仕掛ける     しかける                                     to commence, to lay (mines), to set (traps), to wage (war), to challenge\n",
      "   指摘      してき                                                                                 pointing out, identification\n",
      "   情勢    じょうせい                                                                        state of things, condition, situation\n",
      "   剃る       する                                                                                                     to shave\n",
      "   勢力    せいりょく                                                    influence, power, might, strength, potency, force, energy\n",
      "   選挙     せんきょ                                                                                                     election\n",
      "   戦力    せんりょく                                                                                                war potential\n",
      "   増強    ぞうきょう                                                                                 augment, reinforce, increase\n",
      "   他意       たい          ill will, malice, another intention, secret purpose, ulterior motive, fickleness, double-mindedness\n",
      "   対応     たいおう                                                       interaction, correspondence, coping with, dealing with\n",
      "   対面     たいめん                                                                                           interview, meeting\n",
      "   対話      たいわ                                                             interactive, interaction, conversation, dialogue\n",
      "  高まる     たかまる                                                                            to rise, to swell, to be promoted\n",
      "    丈       だけ                                                                                               only, just, as\n",
      "   秩序     ちつじょ                                                                            order, regularity, system, method\n",
      "   吐く       つく                                                   1. to breathe, 2. to tell (lies), 3. to vomit, to disgorge\n",
      "  強まる     つよまる                                                                              to get strong, to gain strength\n",
      "  強める     つよめる                                                                                  to strengthen, to emphasize\n",
      "    的       てき                                                                                                       #NAME?\n",
      "  NaN        と                                                         1. if (conjunction), 2. promoted pawn (shogi) (abbr)\n",
      "   動向     どうこう                                                                          trend, tendency, movement, attitude\n",
      "   同盟     どうめい                                                                                      alliance, union, league\n",
      "    南       なん                                                                                                        south\n",
      "    荷        に                                                                                         load, baggage, cargo\n",
      "    刃        は                                                                                            edge (of a sword)\n",
      "    派        は                                                                                      clique, faction, school\n",
      "   保障     ほしょう                                                             guarantee, security, assurance, pledge, warranty\n",
      "   防衛     ぼうえい                                                                            defense, protection, self-defense\n",
      "    的       まと                                                                                                 mark, target\n",
      "  設ける     もうける                                                                                      to create, to establish\n",
      "    矢        や                                                                                                        arrow\n",
      "    哉        や                                                                                                question mark\n",
      "   要因     よういん                                                                                   primary factor, main cause\n",
      "N2 vocabulary:\n",
      "Kanji Hiragana                                                           English\n",
      "   在る       ある                                                     to live,to be\n",
      "   以降      いこう                                 on and after,hereafter,thereafter\n",
      "   煎る       いる                                                   to parch,to fry\n",
      "   炒る       いる                                                               NaN\n",
      "   外部      がいぶ                                              the outside,external\n",
      "    殻       から                                             shell,husk,hull,chaff\n",
      "   請う       こう                                                 to ask,to request\n",
      "   交流    こうりゅう alternating current,intercourse,(cultural) exchange,intermingling\n",
      "    琴       こと                                              Koto (Japanese harp)\n",
      "   姿勢      しせい                                                  attitude,posture\n",
      "   周辺    しゅうへん            circumference,outskirts,environs,(computer) peripheral\n",
      "    酢        す                                                           vinegar\n",
      "   刷る       する                                                          to print\n",
      "   相互      そうご                                                 mutual,reciprocal\n",
      "  通ずる     つうずる                                                               NaN\n",
      "   点く       つく                              to catch fire,(electricity) comes on\n",
      "   突く       つく                               (1) to thrust,to strike,(2) to poke\n",
      "   次ぐ       つぐ                                     to rank next to,to come after\n",
      "  繋げる     つなげる                                                        to connect\n",
      "   生る       なる                                                     to bear fruit\n",
      "   睨む      にらむ                         to glare at,to scowl at,to keep an eye on\n",
      "   半島     はんとう                                                         peninsula\n",
      "   本来     ほんらい                                   essentially,naturally,by nature\n",
      "   巡る      めぐる                                                      to go around\n",
      "   有料    ゆうりょう                                               admission-paid,toll\n",
      "   因る       よる                                                      to come from\n"
     ]
    }
   ],
   "source": [
    "def match_vocabulary(input_dataframe, vocabulary_dataframes, language_level):\n",
    "    # Set display options to show all rows\n",
    "    pd.set_option('display.max_rows', None)\n",
    "\n",
    "    matching_tokens = {}\n",
    "\n",
    "    # Define the language levels in order\n",
    "    language_levels = ['N5', 'N4', 'N3', 'N2', 'N1']\n",
    "\n",
    "    for filename, vocabulary_df in vocabulary_dataframes.items():\n",
    "        # Get Level from file_name the filename is in the two first characters\n",
    "        level = filename[:2].upper()\n",
    "\n",
    "        # Get the input_dataframe lemma column\n",
    "        input_lemmas = input_dataframe['lemma']\n",
    "\n",
    "        if language_levels.index(level) > language_levels.index(language_level.upper()):\n",
    "            print(f'languague level {level} is higher than {language_level.upper()}')\n",
    "            # Get the kanji column\n",
    "            kanji_list = vocabulary_df['Kanji']\n",
    "            # Get the hiragana column\n",
    "            hiragana_list = vocabulary_df['Hiragana']\n",
    "\n",
    "            # If input_lemmas contains any of the kanji_list or hiragana_list save all the row in a new dataframe\n",
    "            matching_kanji = input_lemmas[input_lemmas.isin(kanji_list)]\n",
    "            matching_hiragana = input_lemmas[input_lemmas.isin(hiragana_list)]\n",
    "\n",
    "            matching_rows = vocabulary_df[\n",
    "                (vocabulary_df['Kanji'].isin(matching_kanji)) |\n",
    "                (vocabulary_df['Hiragana'].isin(matching_hiragana))\n",
    "            ]\n",
    "\n",
    "            if not matching_rows.empty:\n",
    "                matching_tokens[level] = matching_rows\n",
    "\n",
    "    # Display each level matching tokens\n",
    "    if matching_tokens:\n",
    "        for level, matching_tokens_df in matching_tokens.items():\n",
    "            print(f'{level} vocabulary:')\n",
    "            print(matching_tokens_df.to_string(index=False))  # Print DataFrame without index\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Match the tokens\n",
    "    input_token_dataframe = read_json_files('../data/news/*.json')\n",
    "    vocaabulary_dataframes = read_csv_files('../data/vocabulary/*.csv')\n",
    "\n",
    "    match_vocabulary(input_token_dataframe, vocabulary_dataframes, 'N3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
